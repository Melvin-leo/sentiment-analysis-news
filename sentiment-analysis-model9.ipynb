{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# Model is using 8000 positive and 8000 negative\n",
    "# 4000 tweets are general positive while 4000 are airlines for positive sentiments\n",
    "# 2400 are disaster  and news tweets, 3000 tweets are negative airline sentiments and 2500 general negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('clean_tweet_model9.csv')\n",
    "# Keeping only the neccessary columns\n",
    "data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('news_tests.csv')\n",
    "# Keeping only the neccessary columns\n",
    "test_data = test_data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22216\n",
      "15798\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: str(x))\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "print(data[ data['sentiment'] == 'Positive'].size)\n",
    "print(data[ data['sentiment'] == 'Negative'].size)\n",
    "    \n",
    "max_features = 3000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X_train = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X_train = pad_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "test_data['text'] = test_data['text'].apply(lambda x: str(x))\n",
    "test_data['text'] = test_data['text'].apply(lambda x: x.lower())\n",
    "test_data['text'] = test_data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "print(test_data[ test_data['sentiment'] == 'Positive'].size)\n",
    "print(test_data[ test_data['sentiment'] == 'Negative'].size)\n",
    "    \n",
    "tokenizer_test = Tokenizer(num_words=max_features, split=' ')\n",
    "X_test = tokenizer.texts_to_sequences(test_data['text'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 222, 128)          384000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 222, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 639,194\n",
      "Trainable params: 639,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19007, 222) (19007, 2)\n",
      "(2006, 222) (2006, 2)\n"
     ]
    }
   ],
   "source": [
    "Y_train = pd.get_dummies(data['sentiment']).values\n",
    "Y_test = pd.get_dummies(test_data['sentiment']).values\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      " - 458s - loss: 0.4834 - acc: 0.7603\n",
      "Epoch 2/12\n",
      " - 467s - loss: 0.3751 - acc: 0.8339\n",
      "Epoch 3/12\n",
      " - 419s - loss: 0.3386 - acc: 0.8511\n",
      "Epoch 4/12\n",
      " - 433s - loss: 0.3081 - acc: 0.8673\n",
      "Epoch 5/12\n",
      " - 388s - loss: 0.2880 - acc: 0.8730\n",
      "Epoch 6/12\n",
      " - 448s - loss: 0.2679 - acc: 0.8853\n",
      "Epoch 7/12\n",
      " - 456s - loss: 0.2505 - acc: 0.8924\n",
      "Epoch 8/12\n",
      " - 428s - loss: 0.2338 - acc: 0.9005\n",
      "Epoch 9/12\n",
      " - 412s - loss: 0.2138 - acc: 0.9117\n",
      "Epoch 10/12\n",
      " - 409s - loss: 0.1985 - acc: 0.9175\n",
      "Epoch 11/12\n",
      " - 464s - loss: 0.1838 - acc: 0.9239\n",
      "Epoch 12/12\n",
      " - 401s - loss: 0.1687 - acc: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f8e97b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 12, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.08\n",
      "acc: 0.98\n"
     ]
    }
   ],
   "source": [
    "X_validate = X_test\n",
    "Y_validate = Y_test\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we do love a good storm you double tap if you agree\n",
      "Positive\n",
      "it s so dry here could hardly breathe unbearable\n",
      "Negative\n",
      "we are doing our bit southafrica with a little help from our friends spar this is the st of borehole projects we hope to complete in kwazulunatal\n",
      "Positive\n",
      "caption this throwback to summer in california people\n",
      "Positive\n",
      "salvaged cut and stacked\n",
      "Negative\n",
      "harmful effects of landslides download pdf and find out more only at landslides\n",
      "Negative\n",
      "there possibly couldn t be any road here could there anyways please stay safe wherever you are be sure it s safe to venture out before you do\n",
      "Positive\n",
      "you need a new hobby wanna train for a triathlon with me\n",
      "Positive\n",
      "teamviewer is entertaining\n",
      "Positive\n",
      "modest mouse is the shit\n",
      "Positive\n",
      "you guys must be having a ball looks like you re getting pretty buggered though must be hard\n",
      "Positive\n",
      "in theory that is supposed to work but in reality not so much i keep hitting that x though\n",
      "Negative\n",
      "it has been less than an hour now\n",
      "Positive\n",
      "ate too much\n",
      "Negative\n",
      "is so happy im not sure why just in a good mood\n",
      "Positive\n",
      "i put so much into myself today ahah not really it s all been put into my homework\n",
      "Positive\n",
      "i was at schlotzsky s yesterday\n",
      "Positive\n",
      "it s been a long day goin out to dinner in mins\n",
      "Positive\n",
      "i don t know if granny would actually do it but she d tell him to his face that she would like to do it\n",
      "Positive\n",
      "will upload today photos of the chill out night at the souk cafe\n",
      "Positive\n",
      "on da bridge going back home\n",
      "Positive\n",
      "hope so too except this subject still touches on font despite promising css lectures it doesn t even look at js at all\n",
      "Positive\n",
      "lmao pediphile and you forgot your keys damn let me drink what you ve been drinkin\n",
      "Positive\n",
      "your missing noah gasp haha\n",
      "Positive\n",
      "its been okayy cali s\n",
      "Positive\n",
      "you killed it before i could poke it with fire p\n",
      "Positive\n",
      "none of those are mine\n",
      "Positive\n",
      "yeah i hear ya after all this rain we need to train for time in the sun they shouldn t just spring it on us like this\n",
      "Positive\n",
      "for me haha it s hard for me to bring myself away from the tables getting better now though\n",
      "Positive\n",
      "that s nice i want to be one too but haven t found the right mistress yet\n",
      "Positive\n",
      "their ok\n",
      "Positive\n",
      "oh you have much to learn\n",
      "Positive\n",
      "we have no lives we work x\n",
      "Positive\n",
      "oh dear but do you have pics\n",
      "Positive\n",
      "let s go red wings\n",
      "Positive\n",
      "fuck sounds a bit scary\n",
      "Negative\n",
      "sunburned talking to people under the insanely hot sun\n",
      "Negative\n",
      "welcoming june\n",
      "Positive\n",
      "tom sucks my balls\n",
      "Positive\n",
      "i dont currently have a liking\n",
      "Positive\n",
      "didju just start or are u at a decent level if not u should get a char on drak tharon\n",
      "Positive\n",
      "i think ccna is great for the fundamentals but i think you ll find you learn a lot more when you start working\n",
      "Positive\n",
      "goodnight and goodbye\n",
      "Positive\n",
      "shoutouts fake ass bitches who don t like no one but confusion and strives to divide and try to conquer\n",
      "Negative\n",
      "still in my dress from the ceremonies i feel like i ve been living in my cap and gown for a month graduation on friday night\n",
      "Positive\n",
      "very nice as i m tweeting i m waiting for my yoga class to start\n",
      "Positive\n",
      "the street is in a mess as protesters continue to protest against the government\n",
      "Negative\n",
      "pos_acc 96.18473895582329 %\n",
      "neg_acc 99.10891089108911 %\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X_validate)):\n",
    "    \n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "        \n",
    "    if np.argmax(result) != np.argmax(Y_validate[x]):\n",
    "        print(test_data.values[x][0])\n",
    "        print(test_data.values[x][1])\n",
    "     \n",
    "    \n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "txt = ['major delay in traffic due to accident']\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "txt = tokenizer.texts_to_sequences(txt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "txt = pad_sequences(txt, maxlen=222, dtype='int32', value=0)\n",
    "# print(twt)\n",
    "sentiment = model.predict(txt,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
